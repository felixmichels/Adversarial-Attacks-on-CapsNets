% !TeX root = ba.tex
\appendix
\section*{Appendices}
\addcontentsline{toc}{section}{Appendices}
\renewcommand{\thesubsection}{\Alph{subsection}}

\subsection{Detailed Description of Neural Network Architectures}
\label{lab:networks}

The following tables describe the structure of the neural networks used for the experiments in detail. Each row represents a layer (for brevity's sake some types of layers are merged into a single row).
The tables for the CapsNets are separated into two parts: The encoder network (top) and the decoder network (bottom).
Some expressions may need further explanation:

\begin{itemize}
	\item BN: spatial batch normalization
	\item Conv $K$ $F \times F$, \{valid,same\}: convolutional layer with $K$ filters of shape $F \times F$ and either valid padding (i.e.\ no padding) or same padding (appropriate padding, such that output height and width is equal to that of the input)
	\item FC $n$: fully connected with $n$ units
	\item Densely Connected: a densely connected block \citep{denselyconnected} contains multiple layers in such a way that the input for each layer is the concatenated output of all previous layer in this block.
	\item (Primary) Conv Caps, dim=$d$: a convolutional (primary) capsule layer with capsules of dimension $d$ as explained in \Cref{sec:capsules}. Takes same further arguments as an ordinary convolutional layer.
	\item Dense Caps, dim=$d$: a dense capsule layer with capsules of dimension $d$ as explained in \Cref{sec:capsules}.
\end{itemize}

\begin{table}
	\centering
	
	\begin{tabular}{lc}
		\toprule 
		Layer	&  Output Shape \\ 
		\midrule 
		Conv $64$ $9\times9$, valid, ReLU, BN & $24\times24\times64$ \\ 
		\midrule 
		Primary Conv Caps, $32$ $9\times9$, dim=$8$, stride=2	&  $8\times8\times32\times8$ \\ 
		\midrule 
		Dense Caps, dim=$16$	& $10\times16$ \\ 
		\midrule 
		& \\
		\midrule
		FC $512$, ReLU	& $512$ \\
		\midrule
		FC $1024$, ReLU	& $1024$ \\
		\midrule
		FC $784$, sigmoid	& $784$ \\
		\bottomrule
	\end{tabular} 
	\caption{CapsNet architecture for MNIST}
	\label{tab:capsnet:mnist}

	\vspace{0.75cm}
	
	\begin{tabular}{lc}
		\toprule 
		Layer	&  Output Shape \\ 
		\midrule 
		Conv $32$ $5\times5$, same,	ReLU & $28\times28\times32$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.15$, BN	&  $14\times14\times32$ \\ 
		\midrule 
		Conv $64$ $3\times3$, same, ReLU	& $14\times14\times64$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.15$, BN	& $7\times7\times64$ \\
		\midrule
		Conv $128$ $3\times3$, same, ReLU	& $7\times7\times128$ \\
		\midrule
		Dropout $0.15$, BN	& $7\times7\times128$ \\
		\midrule
		FC $1024$, ReLU, Dropout $0.5$ & $1024$ \\
		\midrule
		FC $10$ & $10$\\
		\bottomrule
	\end{tabular} 
	\caption{ConvNet architecture for MNIST}
	\label{tab:convnet:mnist}
\end{table}


\begin{table}
	\centering
	
	\begin{tabular}{lc}
		\toprule
		Layer	& Output Shape \\ 
		\midrule 
		Conv $32$ $3\times3$, valid, ReLU, BN	&  $26\times26\times32$ \\ 
		\midrule 
		Conv $32$ $3\times3$, valid, Leaky ReLU, BN	&  $24\times24\times32$\\ 
		\midrule 
		Primary Conv Caps, $16$ $9\times9$, dim=$8$	stride=$2$ &  $8\times8\times16\times8$\\ 
		\midrule 
		Dense Caps, dim=$16$	&  $10\times16$\\ 
		\midrule 
		& \\
		\midrule
		FC $512$, ReLU	& $512$ \\
		\midrule
		FC $1024$, ReLU	& $1024$ \\
		\midrule
		FC $784$, sigmoid & $784$ \\
		\bottomrule
	\end{tabular}
	\caption{CapsNet architecture for Fashion-MNIST}
	\label{tab:capsnet:fashion}
	
	\vspace{0.75cm}
	
	\begin{tabular}{lc}
		\toprule 
		Layer	&  Output Shape \\ 
		\midrule
		Conv $32$ $5\times5$, same,	ReLU & $28\times28\times32$ \\ 
		\midrule
		Max-Pooling $2\times2$, Dropout $0.15$, BN	&  $14\times14\times32$ \\ 
		\midrule 
		Conv $64$ $3\times3$, same, ReLU	& $14\times14\times64$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.15$, BN	& $7\times7\times64$ \\
		\midrule
		Conv $128$ $3\times3$, same, ReLU	& $7\times7\times128$ \\
		\midrule
		Dropout $0.15$, BN	& $7\times7\times128$ \\
		\midrule
		FC $1024$, ReLU, Dropout $0.5$ & $1024$ \\
		\midrule
		FC $10$ & $10$\\
		\bottomrule
	\end{tabular} 
	\caption{ConvNet architecture for Fashion-MNIST}
	\label{tab:convnet:fashion}
\end{table}


\begin{table}
	\centering
	
	\begin{tabular}{lc}
		\toprule 
		Layer	& Output Shape \\ 
		\midrule 
		Conv $64$ $5\times5$, valid, ReLU, BN	&  $28\times28\times64$ \\ 
		\midrule 
		Conv $256$ $5\times5$, valid, Leaky ReLU, BN	&  $24\times24\times256$\\ 
		\midrule 
		Primary Conv Caps, $64$ $9\times9$, dim=$8$	stride=$2$ &  $8\times8\times64\times8$\\ 
		\midrule 
		Dense Caps, dim=$16$	&  $10\times16$\\ 
		\midrule
		& \\
		\midrule
		FC $2048$, ReLU	& $2048$ \\
		\midrule
		FC $4096$, ReLU	& $4096$ \\
		\midrule
		FC $3072$, sigmoid	& $3072$\\
		\bottomrule
	\end{tabular}
	\caption{CapsNet architecture for SVHN}
	\label{tab:capsnet:svhn}
	
	\vspace{0.75cm}
	
	\begin{tabular}{lc}
		\toprule 
		Layer	&  Output Shape \\ 
		\midrule 
		Conv $32$ $5\times5$, same,	ReLU & $32\times32\times32$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.15$, BN	&  $16\times16\times32$ \\ 
		\midrule 
		Conv $64$ $3\times3$, same, ReLU	& $16\times16\times64$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.15$, BN	& $8\times8\times64$ \\
		\midrule
		Conv $128$ $3\times3$, same, ReLU	& $8\times8\times128$ \\
		\midrule
		Dropout $0.15$, BN	& $8\times8\times128$ \\
		\midrule
		FC $1024$, ReLU, Dropout $0.5$ & $1024$ \\
		\midrule
		FC $10$ & $10$\\
		\bottomrule
	\end{tabular}
	\caption{ConvNet architecture for SVHN}
	\label{tab:convnet:svhn}
\end{table}


\begin{table}
	\centering

	\begin{tabular}{lc}
		\toprule
		Layer	&  Output Shape \\ 
		\midrule
		Densely Connected with \\
		one Conv $29$ $3\times3$, ReLU and  & $32\times32\times256$ \\
		seven BN, Conv $32$ $3\times3$, ReLU, BN \\ 
		\midrule
		Dropout $0.2$, BN & $32\times32\times256$ \\
		\midrule
		Primary Conv Caps, $32$ $5\times5$, dim=$12$, stride=$2$	&  $14\times14\times32\times12$ \\ 
		\midrule
		Conv Caps, $64$ $3\times3$, dim=$24$, stride=$2$	&  $6\times6\times64\times24$ \\ 
		\midrule
		Dense Caps, dim=$48$ & $10\times48$ \\ 
		\midrule
		& \\
		\midrule
		Densely Connected with two FC $1024$, ReLU & $2048$ \\
		\midrule
		FC $2048$, ReLU	& $2048$ \\
		\midrule
		FC $3072$, sigmoid	& $3072$ \\
		\bottomrule
	\end{tabular} 
	\caption[CapsNet architecture for CIFAR-10]{CapsNet architecture for CIFAR-10
	(uses none-of-the-above category in dynamic routing between all capsule layers)}
	\label{tab:capsnet:cifar10}
	
	\vspace{0.75cm}
	
	\begin{tabular}{lc}
		\toprule
		Layer	&  Output Shape \\ 
		\midrule
		Conv $32$ $5\times5$, same,	ReLU & $32\times32\times32$ \\ 
		\midrule 
		Conv $32$ $5\times5$, same,	ReLU & $32\times32\times32$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.1$, BN	&  $16\times16\times32$ \\ 
		\midrule 
		Conv $64$ $3\times3$, same, ReLU	& $16\times16\times64$ \\ 
		\midrule 
		Conv $64$ $3\times3$, same, ReLU	& $16\times16\times64$ \\ 
		\midrule 
		Max-Pooling $2\times2$, Dropout $0.1$, BN	& $8\times8\times64$ \\
		\midrule
		Conv $128$ $3\times3$, same, ReLU	& $8\times8\times128$ \\
		\midrule
		Max-Pooling $2\times2$, Dropout $0.1$, BN	& $4\times4\times128$ \\
		\midrule
		FC 1024, ReLU, Dropout $0.5$ & $1024$ \\
		\midrule
		FC $10$ & $10$\\
		\bottomrule
	\end{tabular} 
	\caption{ConvNet architecture for CIFAR-10}
	\label{tab:convnet:cifar10}
\end{table}

\subsection{Adversarial Examples}
\label{lab:images}

The following pages display adversarial examples categorized by attack.
The pixel values for the perturbations are scaled for visibility in the following way:
\begin{equation*}
\delta_{visible} \gets \frac{1}{2}\frac{\delta + 1}{\hspace{0.6em} \norm[\infty]{\delta}}
\text{ .}
\end{equation*}
Because of the restriction $x + \delta \in [0,1]^n$ we have $\delta \in [-1,1]^n$ and $\delta_{visible} \in [0,1]^n$.

All images are chosen at random.

\begin{figure}
	\centering
	
	\begin{subfigure}{.23\textwidth}
		\centering
		\includegraphics[width=.743478\textwidth, left]{carlini_wagner_orig_appendix.pdf}%
		\caption{Original}%
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, center]{carlini_wagner_caps_appendix.pdf}%
		\caption{CapsNet}
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, right]{carlini_wagner_conv_appendix.pdf}%
		\caption{ConvNet}
	\end{subfigure}
	\caption[Carlini-Wagner adversarial examples]{Carlini-Wagner adversarial examples and perturbations. Pixel values of perturbation images are scaled for visibility.}
	\label{fig:carlini-wagner-img}
	
\end{figure}


\begin{figure}
	\centering
	
	\begin{subfigure}{.23\textwidth}
		\centering
		\includegraphics[width=.743478\textwidth, left]{deepfool_orig_appendix.pdf}%
		\caption{Original}%
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, center]{deepfool_caps_appendix.pdf}%
		\caption{CapsNet}
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, right]{deepfool_conv_appendix.pdf}%
		\caption{ConvNet}
	\end{subfigure}
	\caption[DeepFool adversarial examples]{DeepFool adversarial examples and perturbations. Pixel values of perturbation images are scaled for visibility.}
	\label{fig:deepfool-img}
	
\end{figure}

\begin{figure}
	\centering
	
	\begin{subfigure}{.23\textwidth}
		\centering
		\includegraphics[width=.743478\textwidth, left]{boundary_attack_orig_appendix.pdf}%
		\caption{Original}%
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, center]{boundary_attack_caps_appendix.pdf}%
		\caption{CapsNet}
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, right]{boundary_attack_conv_appendix.pdf}%
		\caption{ConvNet}
	\end{subfigure}
	\caption[Boundary attack adversarial examples]{Boundary attack adversarial examples and perturbations. Pixel values of perturbation images are scaled for visibility.}
	\label{fig:boundary-img}
	
\end{figure}

\begin{figure}
	\centering
	
	\begin{subfigure}{.23\textwidth}
		\centering
		\includegraphics[width=.743478\textwidth, left]{universal_perturbation_orig_appendix.pdf}%
		\caption{Original}%
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, center]{universal_perturbation_caps_appendix.pdf}%
		\caption{CapsNet}
	\end{subfigure}%
	\begin{subfigure}{.36\textwidth}
		\centering
		\includegraphics[width=.95\textwidth, right]{universal_perturbation_conv_appendix.pdf}%
		\caption{ConvNet}
	\end{subfigure}
	\caption[Universal adversarial examples]{Universal adversarial examples and perturbations. Pixel values of perturbation images are scaled for visibility.}
	\label{fig:universal-img}
	
\end{figure}

\subsection{ICML Paper}

Our work resulted in a paper \citep*{mine} that was accepted as a poster presentation at the ICML 2019 Workshop on the Security and Privacy of Machine Learning.

\includepdf[pages=-, scale=.95]{icml.pdf}

\subsection{Source Code}

All of our source code used for this thesis is available at \url{https://github.com/felixmichels/Adversarial-Attacks-on-CapsNets}

We use Python 3.6 and Tensorflow 1.8.
Below are excerpts from our implementation of the adversarial attacks.

\subsubsection{Carlini-Wagner Attack}
\lstinputlisting[firstline=7]{../../code/attacks/cw.py}

\subsubsection{Boundary Attack}
\lstinputlisting[firstline=7]{../../code/attacks/boundary_attack.py}

\subsubsection{DeepFool Attack}
\lstinputlisting[firstline=7]{../../code/attacks/deepfool.py}

\subsubsection{Universal Adversarial Perturbation}
\lstinputlisting[firstline=7]{../../code/attacks/universal_perturbation.py}

\lstinputlisting[firstline=30]{../../code/attacks/fast_batch_attacks.py}

