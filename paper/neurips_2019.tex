\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
     \usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{amsmath}        
\usepackage{booktabs}

\title{Adversarial Attacks on Capsule Networks}
\bibliographystyle{plain}
% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.



\author{%
  Felix Michels, Tobias Uelwer, Stefan Harmeling \\
  Department of Computer Science\\
  Heinrich-Heine University DÃ¼sseldorf\\
  \texttt{\{felix.michels, tobias.uelwer, harmeling\}@hhu.de} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}
\begin{document}

\maketitle

\begin{abstract}
	In this paper we want to extensively evaluate the robustness of capsule networks towards different adversarial attacks. Our experiments show that capsule networks can be fooled as easily as convolutional networks.

\end{abstract}

\section{Introduction}

Adversarial attacks on capsule networks have been previously studied by Marchisio et al. \cite{marchisio}, however... This paper is structured as followed: In section \ref{lab:capsules} we recapitulate the idea of capsule networks that were introduced by Sabour et al. \cite{capsules}. In section \ref{lab:attacks} we describe the methods used to attack neural networks. Section \ref{lab:experiments} summarizes the results of our experiments.

\section{Capsule Networks and Dynamic Routing}
\label{lab:capsules}

TODO: Wait for Eric to respond.
\cite{capsules}

\section{Adversarial Attacks}
\label{lab:attacks}

Adversarial attacks can be performed in different settings: in the white-box setting the attacker can compute the gradient of the networks output with respect to the input, whereas in the black-box setting such calculations are not possible. Furthermore, adversarial attacks can be classified into targeted attacks, where the goal of the attack is that the network assigns a given label to the manipulated image, and untargeted attacks, where the attacker's goal is to fool the network in the sense that it only missclassifies a given image.

Throughout this paper we denote the input image as $x\in [0,1]^{n\times n}$, the neural network's output after the softmax activation as $F$ and the perturbation as $\delta$. Furthermore, we refer to the i-the entry of $F(x)$ as $F(x)_i$.

\subsection{Carlini-Wagner Attack}

The Carlini-Wagner attack \cite{carlini} is a targeted white-box attack and performed by solving the following constrained optimization problem

\begin{equation*}
	\begin{aligned}
	& \underset{\delta}{\text{minimize}}
	& & ||\delta||_2 + c \cdot \max(\max_{i\neq t}(F(x+\delta)_i)-F(x)_t, 0) \\
	& \text{subject to}
	& & x+\delta \in [0,1]^{n \times n},
	\end{aligned}
\end{equation*}

where $c>0$ is a positive fixed value. To ensure the box-constraint on $x+\delta$ the authors suggested the following transform of variables 
$$\delta = \frac{1}{2}(\tanh(w)+1)-x,$$ where the $\tanh$-function is applied componentwise. After applying this transform the optimization problem is treated as unconstrained and can be solved in terms of $w$ using Adam \cite{adam}. 

\subsection{Boundary Attack}

The idea of the boundary attack as it was intoduced by Brendel et al. \cite{boundary} is to sample a perturbation which leads to a missclassification of the original image. Additionally, the desired perturbation should have the smallest possible norm. The initial perturbation $\delta$ is componentwise sampled from a uniform distribution $\delta_{ij}\sim \mathcal{U}(0,1)$. Initial perturbation, which are not missclassified, are rejected. During the attack a random walk is performed using a proposal distribution $\mathcal{P}$ where we ensure that $x+\delta$ gets wrongly classified.

TODO: Add orthogonal stuff I do not understand yet.

\subsection{DeepFool Attack}

\cite{deepfool}

\subsection{Universal Adversarial Perturbations}
\cite{universal}

\section{Experiments}
\label{lab:experiments}

\subsection{Datasets}

We train the capsule network on the following benchmark datasets:
\begin{itemize}
	\item MNIST: $28\times28$ grayscale images of digits (60,000/10,000) \cite{mnist}
	\item Fashion-MNIST:  $28\times28$ grayscale images of fashion items (60,000/10,000) \cite{fashion}
	\item SVHN: $32\times32$ color images of house numbers (73,257/26,032) \cite{svhn}
	\item CIFAR10: $32\times32$ color images (50.000/10.000) \cite{cifar}
\end{itemize}
Each dataset is divided into ten different classes.

\subsection{Network Architectures}
TODO: Add description of the networks we used. Report test errors.

\begin{table}[h]
	\centering
	\begin{tabular}{lcccc}
		Network       & MNIST & Fashion-MNIST & SVHN & CIFAR10  \\
		\toprule
		Convolutional neural network &  &  &  &  \\
		Capsule network            &  &  &  &  \\
		
	\end{tabular}
\label{tab:accuracies}
\caption{Test accuracies archived by our networks.}
\end{table}
\section{Conclusion}



\bibliography{neurips_2019}


\end{document}
